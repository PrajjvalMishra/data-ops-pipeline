# Data Ops Pipeline Project

This project demonstrates a complete data operations pipeline using modern data stack tools: Airbyte, dbt, BigQuery, and Looker Studio.

---

## ğŸš€ Tools Used

- **Airbyte** â€“ for ingesting raw data (products, purchases, users)
- **BigQuery** â€“ as the data warehouse
- **dbt (Cloud)** â€“ for transforming raw data into analytical models
- **Looker Studio** â€“ for building dashboards
- *(Optional)* Slack/Zapier â€“ for alerting

---

## ğŸ“‚ Pipeline Overview

### 1. **Data Ingestion (Airbyte â†’ BigQuery)**
- Source tables: `products`, `purchases`, `users`
- Destination: `airbyte_raw` dataset in BigQuery

### 2. **Transformations with dbt**
- dbt models:
  - `fct_orders.sql`
  - `fct_ads.sql`
  - `fct_inventory.sql`
  - `dim_sku.sql`
  - `mrt_kpi_daily.sql` â€“ combines all for final KPIs
- Tests: `not_null`, `numeric`, etc. defined in `schema.yml`
- Project folder structure:
models/
â””â”€â”€ example/
â”œâ”€â”€ fct_orders.sql
â”œâ”€â”€ fct_ads.sql
â”œâ”€â”€ fct_inventory.sql
â”œâ”€â”€ dim_sku.sql
â””â”€â”€ mrt_kpi_daily.sql

markdown
Copy
Edit

### 3. **Testing & Deployment (dbt Cloud)**
- Job created with steps: `dbt deps`, `dbt build`, `dbt test`
- All major tests passed

### 4. **Looker Studio Dashboard**
- Final table: `dbt_pmishra.mrt_kpi_daily`
- KPIs visualized:
- Total Revenue
- Ad Spend
- TACoS
- Days of Cover
- Filters for Date & SKU

---

## âœ… Deliverables

- [x] dbt models and tests
- [x] Airbyte ingestion
- [x] BigQuery transformations
- [x] Dashboard in Looker Studio
- [x] dbt Cloud job with tests

---

## ğŸ”— Links

- **GitHub Repo**: [data-ops-pipeline](https://github.com/PrajjvalMishra/data-ops-pipeline)
- **Looker Studio Dashboard**: *(Insert link if public)*
- **dbt Cloud Job**: *(Screenshot or name)*

---

## ğŸ™‹â€â™‚ï¸ Author

Prajjval Mishra  
Email: prajjvalmishra18@gmail.com  
LinkedIn: [Connect](https://www.linkedin.com/in/prajjval-mishra)
